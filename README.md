# ğŸŒ **AI Chatbot Agent â€“ Project Setup Guide**
ğŸ”— **Live Demo**: [AI Chatbot App](https://deepretrive-hjojxkskkm9pqxfsbpvrsv.streamlit.app/)  

---

## ğŸ“ **About the Project**  
This project is an **AI-powered chatbot** built using **LangGraph**, **FastAPI**, and **Streamlit**. It allows users to interact with AI models from **Groq** and **OpenAI**, with an optional **web search** functionality for enhanced responses.  

### ğŸ”¹ **Tech Stack**  
âœ… **Frontend**: Streamlit (for UI)  
âœ… **Backend**: FastAPI (for API handling)  
âœ… **LLMs**: OpenAI (GPT-4o-mini), Groq (Llama-3.3-70B, Mixtral)  
âœ… **Search**: Tavily Search API (for web-enhanced AI responses)  

### ğŸ›  **How It Works**  
1ï¸âƒ£ **Select AI Model** â€“ Choose between Groq and OpenAI.  
2ï¸âƒ£ **Enter Query** â€“ The chatbot processes user input with **LLMs** and **web search (optional)**.  
3ï¸âƒ£ **Get Smart AI Responses** â€“ The agent responds with intelligence, wit, and precision.  

---

## ğŸ“Œ **Table of Contents**  
1ï¸âƒ£ [Setting Up a Python Virtual Environment](#setting-up-a-python-virtual-environment)  
   - [Using Pipenv](#using-pipenv)  
   - [Using pip and venv](#using-pip-and-venv)  
   - [Using Conda](#using-conda)  
2ï¸âƒ£ [Running the Application](#running-the-application)  

---

## âš™ï¸ **Setting Up a Python Virtual Environment**  

### **1ï¸âƒ£ Using Pipenv**  
ğŸ”¹ **Install Pipenv (if not installed):**  
```bash
pip install pipenv

ğŸ”¹ Install Dependencies:

```bash
pipenv install
```

ğŸ”¹ **Activate the Virtual Environment:**


```bash
pipenv shell
```

### **2ï¸âƒ£ Using pip and venv**
**ğŸ”¹ Create a Virtual Environment:**

```bash

python -m venv venv
```

**ğŸ”¹ Activate the Virtual Environment:**
For macOS/Linux:

```bash
source venv/bin/activate
```
For Windows:

```bash
venv\Scripts\activate
```
**ğŸ”¹ Install Dependencies:**

```bash
pip install -r requirements.txt
```

**3ï¸âƒ£ Using Conda**
**ğŸ”¹ Create a Conda Environment:**

```bash

conda create --name myenv python=3.11
```
**ğŸ”¹ Activate the Conda Environment:**

```bash
conda activate myenv
```
**ğŸ”¹ Install Dependencies:**

```bash
pip install -r requirements.txt
```

**ğŸš€ Running the Application**
**ğŸ”¹ Phase 1: Run AI Agent**
```bash
python ai_agent.py
```
**ğŸ”¹ Phase 2: Start the Backend (FastAPI)**
```bash
python backend.py
```
**ğŸ”¹ Phase 3: Start the Frontend (Streamlit)**
```bash
streamlit run frontend.py
```

âœ… Make sure the backend is running before starting the frontend!
ğŸ¯ Final Steps â€“ Deployment
1ï¸âƒ£ Deploy Backend on Render
Push your FastAPI backend.py to GitHub.
Go to Render and create a new Web Service.
Connect your GitHub repo, select Python as the runtime, and set backend.py as the entry file.
Deploy and copy the Backend URL (e.g., https://your-backend.onrender.com).
2ï¸âƒ£ Deploy Frontend on Streamlit Cloud
Push your frontend.py file to GitHub.
Go to Streamlit Cloud and create a new app.
Connect your GitHub repo and select frontend.py as the main file.
Deploy and get your Live App URL.
ğŸš€ Your AI Chatbot is Now Live! Enjoy! ğŸ‰
```vbnet


This `.md` file is **well-structured, visually appealing, and easy to follow**. ğŸš€ Let me know if you want any modifications! ğŸ¯

```





